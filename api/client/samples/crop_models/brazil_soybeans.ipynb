{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brazil soybeans crop model using Gro API\n",
    "In this notebook, we walk through the process of building a simple \"crop model\" using data in Gro. The accompanying Gro web app display for [Brazil Soybeans](https://app.gro-intelligence.com/displays/25894) provides an overview of the data series we will use. The crop model we will create is a very basic  model that uses crop-production-weighted NDVI to forecast  yield.\n",
    "\n",
    "## Preliminary\n",
    "First we construct a `CropModel` object. We also save the entity ids for the `item` [soybeans](https://app.gro-intelligence.com/dictionary/items/270), the `region` [Brazil](https://app.gro-intelligence.com/dictionary/regions/1029), the `metric` [yield](https://app.gro-intelligence.com/dictionary/metrics/170037) and yield units (sources report yield in different units, we specify tonnes per hectare so they'll be converted to a consistent unit for model training). We will use these throughout the notebook to simplify the retrieval, storage and manipulation of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from api.client.crop_model import CropModel\n",
    "\n",
    "model = CropModel('api.gro-intelligence.com', os.environ['GROAPI_TOKEN'])\n",
    "country_id = model.search_for_entity('regions', \"brazil\")\n",
    "crop_id =  model.search_for_entity('items', \"soybeans\")\n",
    "yield_id = model.search_for_entity('metrics', \"yield mass/area\")\n",
    "TONNES_PER_HECTARE_UNIT_ID = 61"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quiet logs for demonstration purposes:\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import logging\n",
    "logging.disable(level=logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Historical yields\n",
    "To get data series for national level soybeans yield for Brazil, we set the entities (item, metric and region), and get the available data series.  Note that there are multiple data series in this case because there are a few different <em>sources</em> that report the Brazil soybeans yields: [FAO](https://app.gro-intelligence.com/dictionary/sources/2), [PS&D](https://app.gro-intelligence.com/dictionary/sources/14), [IGC](https://app.gro-intelligence.com/dictionary/sources/19), and [IBGE](https://app.gro-intelligence.com/dictionary/sources/114). Each source covers a slightly different time range. Here we simply take all of them to have maximum coverage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yield_entities = {}\n",
    "yield_entities['item_id']  = crop_id\n",
    "yield_entities['region_id'] = country_id\n",
    "yield_entities['metric_id'] = yield_id\n",
    "\n",
    "data_series_list = model.get_data_series(**yield_entities)\n",
    "print(\"There are {} data series for {}.\".format(len(data_series_list), yield_entities))\n",
    "\n",
    "for data_series in data_series_list:\n",
    "    data_series['unit_id'] = TONNES_PER_HECTARE_UNIT_ID\n",
    "    print(\"source_id {}: {} to {}\".format(\n",
    "        data_series['source_id'], data_series['start_date'], data_series['end_date']))\n",
    "    model.add_single_data_series(data_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = model.get_df()\n",
    "yield_df = df.loc[(df.metric_id == yield_entities['metric_id']) & \\\n",
    "                  (df.region_id == yield_entities['region_id'])]\n",
    "yield_df.end_date = pandas.to_datetime(yield_df.end_date)\n",
    "yield_df.set_index('end_date')\n",
    "fig, axes = plt.subplots(1, 1)\n",
    "for source_id, group in yield_df.groupby('source_id'):\n",
    "    group.plot(x='end_date', y='value', ax=axes, \n",
    "               label=model.lookup('sources', source_id)['name'])\n",
    "plt.ylabel(\"Yield (t/ha)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Production \"weight\" of provinces\n",
    "We compute the \"weight\" of each province, based on the full history of production quantity per province. The weights are normalized to add up to 1.0. A weight of 0.2 means we expect that province to account for 20% of the country's production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "provinces = model.get_provinces(\"brazil\")\n",
    "weights = model.compute_weights(\"soybeans\", \"Production Quantity mass\", provinces)\n",
    "max_weight = max(filter(lambda x: x >0, weights))\n",
    "print ('Total weight: {}'.format(sum(filter(lambda x: x >0, weights))))\n",
    "print ('Maximum weight: {}'.format(max_weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import geopandas\n",
    "from shapely.geometry import shape\n",
    "\n",
    "gdf = geopandas.GeoDataFrame([{\n",
    "       'region_id': province['id'], \n",
    "       'geometry': shape(model.get_geojson(province['id'])['geometries'][0]),\n",
    "       'production_weight': weight if weight > 0 else 0\n",
    "    } for (province, weight) in zip(provinces, weights)])\n",
    "gdf.set_index('region_id')\n",
    "\n",
    "fig, axes = plt.subplots(1, 1)\n",
    "gdf.plot(column='production_weight', \n",
    "         cmap='Blues', ax=axes, vmin=0, vmax=max_weight, legend=True)\n",
    "axes.set_title('Crop Production Weight')\n",
    "axes.xaxis.set_visible(False)\n",
    "axes.yaxis.set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NDVI, province level\n",
    "The main signal we will use to model crop yields is [NDVI](https://app.gro-intelligence.com/dictionary/items/321), which represents vegetation biomass per pixel, and thus is a good physical proxy for yield (production mass per unit of area).\n",
    "\n",
    "First we load the historical data for province level NDVI.  Here, there  are actually two data series for each region, one with `8-day` and one with `16-day` periods. We choose to use the series with 8-day (frequency_id = 3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities = {}\n",
    "entities['item_id'] =  model.search_for_entity('items', \"Vegetation NDVI\")\n",
    "entities['metric_id'] = model.search_for_entity('metrics', \"Vegetation Indices index\")\n",
    "EIGHT_DAY_FREQUENCY_ID = 3\n",
    "entities['frequency_id'] = EIGHT_DAY_FREQUENCY_ID\n",
    "\n",
    "for province in provinces:\n",
    "    entities['region_id'] = province['id']\n",
    "    for data_series in model.get_data_series(**entities):\n",
    "        model.add_single_data_series(data_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NDVI crop-weighted, province level\n",
    "NDVI represents the biomass  of <em>all</em> vegetation, not just soybeans. To make it a more accurate signal, we compute the crop-weighted version of NDVI, using [compute_crop_weighted_series](https://developers.gro-intelligence.com/api.html#api.client.crop_model.CropModel.compute_crop_weighted_series). Note that NDVI data series exist at different frequencies, and this method will compute the crop weighted version for all frequencies. Here we will limit ourselves to the 8-day frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soy_ndvi_df = model.compute_crop_weighted_series(\n",
    "    'soybeans', 'Production Quantity mass',\n",
    "    'Vegetation NDVI', 'Vegetation Indices index',\n",
    "    provinces)\n",
    "soy_ndvi_df = soy_ndvi_df.loc[soy_ndvi_df.frequency_id == EIGHT_DAY_FREQUENCY_ID]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at NDVI by province, on a particular date. First, we select NDVI for all provinces from the model's dataframe, and join it with the geopandas dataframe that has the provinces geometry.   Second, we select the crop weighted NDVI for all provinces from the `soy_ndvi_df` dataframe and do the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EVAL_DATE = u'2019-02-25T00:00:00.000Z'\n",
    "df = model.get_df()\n",
    "ndvi_df = df.loc[(df.metric_id == entities['metric_id']) & \\\n",
    "                 (df.end_date == EVAL_DATE),:]\n",
    "gdf1 = gdf.join(ndvi_df.set_index('region_id'), on='region_id')\n",
    "\n",
    "cwndvi_df = soy_ndvi_df.loc[(soy_ndvi_df.metric_id == entities['metric_id']) & \\\n",
    "                            (soy_ndvi_df.end_date == EVAL_DATE), :]\n",
    "gdf2 = gdf.join(cwndvi_df.set_index('region_id'), on='region_id')\n",
    "\n",
    "fig, axes = plt.subplots(1, 2)\n",
    "gdf1.plot(column='value', \n",
    "          cmap='Greens', ax=axes[0], vmin=0.0, vmax=1.0)\n",
    "axes[0].set_title('NDVI')\n",
    "axes[0].xaxis.set_visible(False)\n",
    "axes[0].yaxis.set_visible(False)\n",
    "gdf2.plot(column='value', \n",
    "          cmap='Greens', ax=axes[1], vmin=0.0, vmax=max_weight)\n",
    "axes[1].set_title('Crop-weighted NDVI')\n",
    "axes[1].xaxis.set_visible(False)\n",
    "axes[1].yaxis.set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NDVI, country level\n",
    "NDVI is available as a data series at all region levels, so we just add it to the model at the country level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities['region_id'] = country_id\n",
    "for data_series in model.get_data_series(**entities):\n",
    "    model.add_single_data_series(data_series)\n",
    "df = model.get_df()\n",
    "df.end_date = pandas.to_datetime(df.end_date, utc=True)\n",
    "country_ndvi_df = df.loc[(df.metric_id == entities['metric_id']) & \\\n",
    "                         (df.region_id == entities['region_id'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For crop weighted NDVI, we need to aggregate it up from provinces. Since the crop-weighted NDVI series was built with weights normalized to 1.0, the sum of province level values is the national level value, for each date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soy_ndvi_df.end_date = pandas.to_datetime(soy_ndvi_df.end_date, utc=True)\n",
    "soy_ndvi_df.set_index('end_date')\n",
    "country_ndvi_df.set_index('end_date')\n",
    "\n",
    "country_ndvi_df = country_ndvi_df.merge(pandas.DataFrame([{\n",
    "    'end_date': end_date,\n",
    "    'crop_weighted_value': value\n",
    "} for (end_date, value) in zip(soy_ndvi_df.end_date, \n",
    "                               soy_ndvi_df.groupby(['end_date']).sum().value)]))\n",
    "\n",
    "fig, axes = plt.subplots(1, 1)\n",
    "country_ndvi_df.plot(x='end_date', y=['crop_weighted_value', 'value'], ax=axes)\n",
    "plt.ylabel('NDVI')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relationship between  yield and crop-weighted NDVI\n",
    "On any day during the season, we can look at crop weighted NDVI as a rough aproximation of the amount of soybeans being grown per unit of area. Let's see if this would work as a predictor of the final yield of the crop for the current year. For this example, we pick February 25th of each year, which, as we can see from the crop calendar for this crop on our [display](https://app.gro-intelligence.com/displays/25894), is the end of the growth period, and just before harvesting starts.  This date is late enough in the season (end of growth) that the weighted NDVI should represent the final amount of the crop that will be produced, but it is early enough (before harvest) for the forecast to be useful.  Let's look at a scatter plot of historical values of  crop weighted NDVI on Feb 25 and final yields for the same year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "PREDICTION_DATE_MONTH = 2\n",
    "PREDICTION_DATE_DAY = 25\n",
    "tmp_df = country_ndvi_df.loc[(country_ndvi_df.metric_id == entities['metric_id']) & \\\n",
    "                             (country_ndvi_df.region_id == country_id) & \\\n",
    "                             (country_ndvi_df.end_date.map(lambda x: x.month) == PREDICTION_DATE_MONTH) &\\\n",
    "                             (country_ndvi_df.end_date.map(lambda x: x.day) == PREDICTION_DATE_DAY),:]\n",
    "ym_df = pandas.DataFrame([{'year': end_date.year, 'yield': value}\n",
    "                          for (end_date, value) in zip(yield_df.end_date, \n",
    "                                                   yield_df.value)])\n",
    "cw_df = pandas.DataFrame([{'year': end_date.year, 'crop_weighted_ndvi': value}\n",
    "                          for (end_date, value) in zip(tmp_df.end_date,\n",
    "                                                       tmp_df.crop_weighted_value)])\n",
    "ym_df = ym_df.merge(cw_df)\n",
    "ym_df.plot.scatter(x='crop_weighted_ndvi', y = 'yield')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed there seems to be a relationship between these two series, which means weighted NDVI on Feb 25 can be a reasonable predictor of final yield.\n",
    "\n",
    "## Linear model\n",
    "An obvious next step is to do a linear regression, where we model `y = a * x + b` where x is the crop weighted NDVI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "lm = linear_model.LinearRegression()\n",
    "X = ym_df.loc[:,['crop_weighted_ndvi']]\n",
    "lm.fit(X, ym_df['yield'])\n",
    "lm_df =pandas.DataFrame([{'year': year, 'lm_yield': value}\n",
    "                         for (year, value) in zip(ym_df.year, lm.predict(X))])\n",
    "plt.scatter(ym_df['yield'], (lm_df['lm_yield']))\n",
    "plt.xlabel(\"Actual yield\")\n",
    "plt.ylabel(\"Predicted yield (t/ha)\")\n",
    "plt.plot([min(ym_df['yield']), max(ym_df['yield'])], \n",
    "         [min(ym_df['yield']), max(ym_df['yield'])], color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is not a great fit, especially at higher yields, which is not surprising as we're using crop weights based on production rather than planted area.  Ideally to get the national yield, we would weight regional NDVI by  area.  Since production equals area multiplied by yield,  weighting by production instead of area will tend to over-wheight the high yield regions. Thus the model will be less accurate in years when the difference between regions is relatively large.\n",
    "\n",
    "##  Quadratic+trend model\n",
    "A polynomial of degree 2 should help us capture this second order effect, and provide a better fit. So we try to fit  `y = a * x^2 + b * x + c` where x is the  crop weighted NDVI. Further, as there appears to be a longer term trend of improvement in yields, we add the year as another dependent variable to capture the long term trend. So the model becomes `y = a * x^2 + b * x + c + d * t`, where t is time (year)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = pandas.DataFrame(X.crop_weighted_ndvi.map(lambda x: x*x))\n",
    "X2.rename(columns={'crop_weighted_ndvi': 'crop_weighted_ndvi2'}, inplace=True)\n",
    "X2 = pandas.DataFrame([X2.crop_weighted_ndvi2, X.crop_weighted_ndvi, ym_df.year]).transpose()\n",
    "qm = linear_model.LinearRegression()\n",
    "qm.fit(X2, ym_df['yield'])\n",
    "qm_df =pandas.DataFrame([{'year': year, 'qm_yield': value}\n",
    "                         for (year, value) in zip(ym_df.year, qm.predict(X2))])\n",
    "plt.scatter(ym_df['yield'], (qm_df['qm_yield']))\n",
    "plt.plot([min(ym_df['yield']), max(ym_df['yield'])], \n",
    "         [min(ym_df['yield']), max(ym_df['yield'])], color='red')\n",
    "plt.xlabel(\"Actual yield (t/ha)\")\n",
    "plt.ylabel(\"Predicted yield (t/ha)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "The second model seems to provide a better looking fit. Looking at the standard regression statistics to confirm that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "print('''Linear Model:\n",
    "      Mean Squared Error: {}\n",
    "      R2: {}'''.format(mean_squared_error(ym_df['yield'], lm.predict(X)),\n",
    "                      r2_score(ym_df['yield'], lm.predict(X))))\n",
    "print('''Quadtratic Model:\n",
    "      Mean Squared Error: {}\n",
    "      R2: {}'''.format(mean_squared_error(ym_df['yield'], qm.predict(X2)),\n",
    "                          r2_score(ym_df['yield'], qm.predict(X2))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed the quadratic+trend model\n",
    "- has a root-mean-square error of about 0.026 t/ha i.e. less than 1% \n",
    "- explains about 72% of the variance in yields\n",
    "\n",
    "To get more perspective, let's see how well the models' fit reality as a function of time. As we can see in the following figure, the quadratic model does indeed outperform the linear model, especially in the high yield years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backtest_df = ym_df.merge(lm_df).merge(qm_df)\n",
    "backtest_df.year = pandas.to_datetime(backtest_df.year, format='%Y')\n",
    "fig, axes = plt.subplots(1, 1)\n",
    "backtest_df.plot(x='year', y = ['yield', 'lm_yield', 'qm_yield'], ax=axes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "A full blown model requires a lot more signals. For example, in a [Gro Yield Model](https://app.gro-intelligence.com/dictionary/sources/32) data series for soybeans in Brazil we would consider:\n",
    "\n",
    "- [evapotranspiration](https://app.gro-intelligence.com/dictionary/items/4395) as an additional input\n",
    "- district level historical yields from [CONAB](https://app.gro-intelligence.com/dictionary/sources/73) instead of only national level as above, and\n",
    "- [pixel-level crop masks](https://github.com/gro-intelligence/api-client/wiki/Gro-crop-masks) to weight the NDVI, instead of the coarser province level production weights.\n",
    "\n",
    "But this extremely simple crop model shows that a quick but reasonable fit (1% in-sample error-rate) can be achieved just using historical yields, production quantity, and NDVI.\n",
    "\n",
    "##  Related links\n",
    "- Gro web app [display](https://app.gro-intelligence.com/displays/25894) accompanying this example\n",
    "- Soybean kit section of the [user manual](https://app.gro-intelligence.com/docs/user-manual#weather-data-soybean)\n",
    "- Gro Yield Model [web page and papers](https://gro-intelligence.com/yield-model/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
